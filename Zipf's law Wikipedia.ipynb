{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\n",
    "    url=\"https://en.wikipedia.org/wiki/Team_sport\",\n",
    ")\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team sport\n"
     ]
    }
   ],
   "source": [
    "title = soup.find(id=\"firstHeading\")\n",
    "print(title.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the links\n",
    "allLinks = soup.find(id=\"bodyContent\").find_all(\"a\")\n",
    "linkToScrape = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through links checking for the `/wiki` prefix\n",
    "for link in allLinks:\n",
    "    if link['href'].find(\"/wiki/\") == -1:\n",
    "        continue\n",
    "    linkToScrape = link\n",
    "    break        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/wiki/Wikipedia:Citing_sources\n"
     ]
    }
   ],
   "source": [
    "print(linkToScrape['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to keep track of visited pages\n",
    "visited = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(url):\n",
    "    \"\"\"Checking if a link is valid\"\"\"\n",
    "    \n",
    "    if url:\n",
    "        if url.startswith('/wiki'):\n",
    "            if not re.compile('/\\w+:').search(url):\n",
    "                return True\n",
    "            \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function that combines these processes into one\n",
    "\n",
    "def scrapeWiki(url):\n",
    "    global visited\n",
    "    if len(visited) > 100:\n",
    "        return\n",
    "        \n",
    "    response = requests.get(\n",
    "        url=url,\n",
    "    )\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    title = soup.find(id=\"firstHeading\")\n",
    "    print(title.text)\n",
    "        \n",
    "    # Get all the links\n",
    "    \n",
    "    allLinks = soup.find(id=\"bodyContent\").find_all(\"a\")\n",
    "    \n",
    "    # Loop through links checking if valid\n",
    "    for link in allLinks:\n",
    "        \n",
    "        link_url = link.get('href', '')\n",
    "        if link_url not in visited and is_valid(link_url):\n",
    "            visited.append(link_url)\n",
    "            break\n",
    "              \n",
    "\n",
    "    scrapeWiki(\"https://en.wikipedia.org\" + link_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team Sport\n",
      "Case sensitivity\n",
      "Case Sensitive (TV series)\n",
      "Crime film\n",
      "Film genre\n",
      "List of genres\n",
      "Literary genre\n",
      "Literature\n",
      "Literature (card game)\n",
      "List of fishes in Canada\n",
      "Canada\n",
      "Canada (disambiguation)\n",
      "Canada Dock\n",
      "Kirkdale, Liverpool\n",
      "Merseyside\n",
      "Metropolitan county\n",
      "Metropolitan and non-metropolitan counties of England\n",
      "Regions of England\n",
      "NUTS 1 statistical regions of England\n",
      "England\n",
      "England (disambiguation)\n",
      "Kingdom of England\n",
      "United Kingdom\n",
      "Great Britain\n",
      "Kingdom of Great Britain\n",
      "Flag of Great Britain\n",
      "Flag of the United Kingdom\n",
      "Union Jack\n",
      "Union flag (disambiguation)\n",
      "Union Jack (disambiguation)\n",
      "Union mark of Norway and Sweden\n",
      "Herring salad\n",
      "Union mark of Norway and Sweden\n",
      "Swedish language\n",
      "Sweden\n",
      "Sweden (disambiguation)\n",
      "Sweden (European Parliament constituency)\n",
      "European Parliament constituency\n",
      "European Union\n",
      "EU (disambiguation)\n",
      "Entropia Universe\n",
      "Video game developer\n",
      "Video game industry\n",
      "Video game design\n",
      "Game design\n",
      "Diamond Trust of London\n",
      "Jason Rohrer\n",
      "Programmer\n",
      "Program\n",
      "Program management\n",
      "Program Manager\n",
      "Windows 3.1x\n",
      "Windows NT 3.1\n",
      "Windows NT\n",
      "Programmer\n",
      "Coding (social sciences)\n",
      "Social science\n",
      "Social studies\n",
      "Education in the United States\n",
      "United States Department of Education\n",
      "U.S. Office of Education\n",
      "Federal government of the United States\n",
      "American Government (textbook)\n",
      "James Q. Wilson\n",
      "Denver\n",
      "Denver (disambiguation)\n",
      "Denver, Victoria\n",
      "Victoria (Australia)\n",
      "Victoria\n",
      "Victoria, British Columbia\n",
      "Greater Victoria\n",
      "Greater Vitória\n",
      "A Grande Vitória\n",
      "Caio Castro\n",
      "Portuguese name\n",
      "Given name\n",
      "Call name (disambiguation)\n",
      "Call sign\n",
      "Callsign (company)\n",
      "Identity fraud\n",
      "Personal data\n",
      "Private Information\n",
      "Fergus McDonell\n",
      "Ticehurst\n",
      "Ticehurst (surname)\n",
      "Burwash\n",
      "Burwash (disambiguation)\n",
      "Burwash, Ontario\n",
      "List of sovereign states\n",
      "Lists of countries and territories\n",
      "Lists by country\n",
      "Sovereign state\n",
      "United Nations\n",
      "United Nations (disambiguation)\n",
      "United Nations (band)\n",
      "New York City\n",
      "New York City (disambiguation)\n",
      "List of ships named New York City\n",
      "USS New York City\n",
      "USS New York\n",
      "USS New York (1776)\n"
     ]
    }
   ],
   "source": [
    "scrapeWiki(\"https://en.wikipedia.org/wiki/Team_Sport\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "print(len(visited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
